{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api  as sm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 9.35192337e-01 7.66490419e-01 ... 3.12696634e-01\n",
      "  5.82379309e-03 0.00000000e+00]\n",
      " [0.00000000e+00 9.78541955e-01 7.70066651e-01 ... 3.13422663e-01\n",
      "  1.04705276e-04 0.00000000e+00]\n",
      " [5.78730497e-06 9.35217023e-01 7.53117667e-01 ... 3.11911316e-01\n",
      "  1.47389219e-02 0.00000000e+00]\n",
      " ...\n",
      " [9.99976851e-01 9.90904812e-01 7.64079694e-01 ... 3.12584864e-01\n",
      "  2.64215395e-03 0.00000000e+00]\n",
      " [9.99976851e-01 9.54208999e-01 7.72855742e-01 ... 3.15245157e-01\n",
      "  3.89238944e-04 0.00000000e+00]\n",
      " [1.00000000e+00 9.49231759e-01 7.65256401e-01 ... 3.13400843e-01\n",
      "  8.44648509e-03 0.00000000e+00]]\n",
      "Dimensions of original Datasets is  (284807, 30)\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "               V1         V2        V3        V4        V5        V6  \\\n",
      "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
      "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
      "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
      "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
      "...           ...        ...       ...       ...       ...       ...   \n",
      "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
      "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
      "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
      "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
      "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
      "\n",
      "              V7        V8        V9       V10  ...       V21       V22  \\\n",
      "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
      "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
      "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
      "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
      "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
      "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
      "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
      "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
      "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 30 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"creditcard.csv\")\n",
    "scaler = MinMaxScaler()\n",
    "new_df = scaler.fit_transform(df)\n",
    "print(new_df)\n",
    "new_df_2=df.drop('Time',axis=1)\n",
    "print(\"Dimensions of original Datasets is \", new_df_2.shape)\n",
    "print(new_df_2.Class.value_counts())\n",
    "print(new_df_2)\n",
    "new_df_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=new_df_2.drop(['Amount'],axis=1)\n",
    "Y=new_df_2['Class']\n",
    "#X, Y = make_classification(n_samples=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Datasets-(Splitting Dataset into Training and Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size(rows) of training data is 227845\n",
      "Size(rows) of testing data is 56962\n",
      "Data types of training data(X) are  V1       float64\n",
      "V2       float64\n",
      "V3       float64\n",
      "V4       float64\n",
      "V5       float64\n",
      "V6       float64\n",
      "V7       float64\n",
      "V8       float64\n",
      "V9       float64\n",
      "V10      float64\n",
      "V11      float64\n",
      "V12      float64\n",
      "V13      float64\n",
      "V14      float64\n",
      "V15      float64\n",
      "V16      float64\n",
      "V17      float64\n",
      "V18      float64\n",
      "V19      float64\n",
      "V20      float64\n",
      "V21      float64\n",
      "V22      float64\n",
      "V23      float64\n",
      "V24      float64\n",
      "V25      float64\n",
      "V26      float64\n",
      "V27      float64\n",
      "V28      float64\n",
      "Class      int64\n",
      "dtype: object\n",
      "Data types of training data(X) are  <bound method NDFrame.describe of               V1        V2        V3        V4        V5        V6        V7  \\\n",
      "223361  1.955041 -0.380783 -0.315013  0.330155 -0.509374 -0.086197 -0.627978   \n",
      "165061 -0.400975 -0.626943  1.555339 -2.017772 -0.107769  0.168310  0.017959   \n",
      "238186  0.072509  0.820566 -0.561351 -0.709897  1.080399 -0.359429  0.787858   \n",
      "150562 -0.535045  1.014587  1.750679  2.769390  0.500089  1.002270  0.847902   \n",
      "138452 -4.026938  1.897371 -0.429786 -0.029571 -0.855751 -0.480406 -0.435632   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "119879  1.173488  0.100792  0.490512  0.461596 -0.296377 -0.213165 -0.165254   \n",
      "259178 -0.775981  0.144023 -1.142399 -1.241113  1.940358  3.912076 -0.466107   \n",
      "131932 -0.146609  0.992946  1.524591  0.485774  0.349308 -0.815198  1.076640   \n",
      "146867 -2.948638  2.354849 -2.521201 -3.798905  1.866302  2.727695 -0.471769   \n",
      "121958  1.233174 -0.784851  0.386784 -0.698559 -1.034018 -0.637028 -0.502369   \n",
      "\n",
      "              V8        V9       V10  ...       V20       V21       V22  \\\n",
      "223361  0.035994  1.054560 -0.030441  ... -0.125390  0.238197  0.968305   \n",
      "165061 -0.401619  0.040378  0.611115  ... -0.470372 -0.153485  0.421703   \n",
      "238186  0.117276 -0.131275 -0.638222  ...  0.012227 -0.314638 -0.872959   \n",
      "150562 -0.081323  0.371579  0.560595  ... -0.253757  0.063525  0.443431   \n",
      "138452  1.313760  0.536044  1.221746  ... -0.012320 -0.480691 -0.230369   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "119879  0.119221 -0.114199  0.079128  ... -0.157534 -0.186027 -0.574283   \n",
      "259178  1.360620  0.400697 -0.654029  ... -0.295730  0.037078 -0.019575   \n",
      "131932 -0.395316 -0.491303 -0.212753  ...  0.007155  0.052649  0.354089   \n",
      "146867  2.217537  0.580199 -0.027572  ...  0.417396 -0.332759 -1.047514   \n",
      "121958 -0.188057 -0.749637  0.543016  ...  0.337732  0.027634 -0.234522   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Class  \n",
      "223361  0.053208 -0.278602 -0.044999 -0.216780  0.045168 -0.047145      0  \n",
      "165061  0.113442 -1.004095 -1.176695  0.361924 -0.370469 -0.144792      0  \n",
      "238186  0.083391  0.148178 -0.431459  0.119690  0.206395  0.070288      0  \n",
      "150562 -0.072754  0.448192 -0.655203 -0.181038 -0.093013 -0.064931      0  \n",
      "138452  0.250717  0.066399  0.470787  0.245335  0.286904 -0.322672      0  \n",
      "...          ...       ...       ...       ...       ...       ...    ...  \n",
      "119879  0.161405 -0.006140  0.091444  0.109235 -0.020922  0.003967      0  \n",
      "259178  0.241830  0.682820 -1.635109 -0.770941  0.066006  0.137056      0  \n",
      "131932 -0.291198  0.402849  0.237383 -0.398467 -0.121139 -0.196195      0  \n",
      "146867  0.143326  0.678869  0.319710  0.426309  0.496912  0.335822      0  \n",
      "121958 -0.059544 -0.109073  0.290326 -0.393074  0.001217  0.038588      0  \n",
      "\n",
      "[227845 rows x 29 columns]>\n",
      "                            \n",
      "Data types of testing data(X) are  V1       float64\n",
      "V2       float64\n",
      "V3       float64\n",
      "V4       float64\n",
      "V5       float64\n",
      "V6       float64\n",
      "V7       float64\n",
      "V8       float64\n",
      "V9       float64\n",
      "V10      float64\n",
      "V11      float64\n",
      "V12      float64\n",
      "V13      float64\n",
      "V14      float64\n",
      "V15      float64\n",
      "V16      float64\n",
      "V17      float64\n",
      "V18      float64\n",
      "V19      float64\n",
      "V20      float64\n",
      "V21      float64\n",
      "V22      float64\n",
      "V23      float64\n",
      "V24      float64\n",
      "V25      float64\n",
      "V26      float64\n",
      "V27      float64\n",
      "V28      float64\n",
      "Class      int64\n",
      "dtype: object\n",
      "Data types of testing  data(X) are  <bound method NDFrame.describe of               V1        V2        V3        V4        V5        V6        V7  \\\n",
      "223361  1.955041 -0.380783 -0.315013  0.330155 -0.509374 -0.086197 -0.627978   \n",
      "165061 -0.400975 -0.626943  1.555339 -2.017772 -0.107769  0.168310  0.017959   \n",
      "238186  0.072509  0.820566 -0.561351 -0.709897  1.080399 -0.359429  0.787858   \n",
      "150562 -0.535045  1.014587  1.750679  2.769390  0.500089  1.002270  0.847902   \n",
      "138452 -4.026938  1.897371 -0.429786 -0.029571 -0.855751 -0.480406 -0.435632   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "119879  1.173488  0.100792  0.490512  0.461596 -0.296377 -0.213165 -0.165254   \n",
      "259178 -0.775981  0.144023 -1.142399 -1.241113  1.940358  3.912076 -0.466107   \n",
      "131932 -0.146609  0.992946  1.524591  0.485774  0.349308 -0.815198  1.076640   \n",
      "146867 -2.948638  2.354849 -2.521201 -3.798905  1.866302  2.727695 -0.471769   \n",
      "121958  1.233174 -0.784851  0.386784 -0.698559 -1.034018 -0.637028 -0.502369   \n",
      "\n",
      "              V8        V9       V10  ...       V20       V21       V22  \\\n",
      "223361  0.035994  1.054560 -0.030441  ... -0.125390  0.238197  0.968305   \n",
      "165061 -0.401619  0.040378  0.611115  ... -0.470372 -0.153485  0.421703   \n",
      "238186  0.117276 -0.131275 -0.638222  ...  0.012227 -0.314638 -0.872959   \n",
      "150562 -0.081323  0.371579  0.560595  ... -0.253757  0.063525  0.443431   \n",
      "138452  1.313760  0.536044  1.221746  ... -0.012320 -0.480691 -0.230369   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "119879  0.119221 -0.114199  0.079128  ... -0.157534 -0.186027 -0.574283   \n",
      "259178  1.360620  0.400697 -0.654029  ... -0.295730  0.037078 -0.019575   \n",
      "131932 -0.395316 -0.491303 -0.212753  ...  0.007155  0.052649  0.354089   \n",
      "146867  2.217537  0.580199 -0.027572  ...  0.417396 -0.332759 -1.047514   \n",
      "121958 -0.188057 -0.749637  0.543016  ...  0.337732  0.027634 -0.234522   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Class  \n",
      "223361  0.053208 -0.278602 -0.044999 -0.216780  0.045168 -0.047145      0  \n",
      "165061  0.113442 -1.004095 -1.176695  0.361924 -0.370469 -0.144792      0  \n",
      "238186  0.083391  0.148178 -0.431459  0.119690  0.206395  0.070288      0  \n",
      "150562 -0.072754  0.448192 -0.655203 -0.181038 -0.093013 -0.064931      0  \n",
      "138452  0.250717  0.066399  0.470787  0.245335  0.286904 -0.322672      0  \n",
      "...          ...       ...       ...       ...       ...       ...    ...  \n",
      "119879  0.161405 -0.006140  0.091444  0.109235 -0.020922  0.003967      0  \n",
      "259178  0.241830  0.682820 -1.635109 -0.770941  0.066006  0.137056      0  \n",
      "131932 -0.291198  0.402849  0.237383 -0.398467 -0.121139 -0.196195      0  \n",
      "146867  0.143326  0.678869  0.319710  0.426309  0.496912  0.335822      0  \n",
      "121958 -0.059544 -0.109073  0.290326 -0.393074  0.001217  0.038588      0  \n",
      "\n",
      "[227845 rows x 29 columns]>\n",
      "                            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              V1        V2        V3        V4        V5        V6        V7  \\\n",
       " 223361  1.955041 -0.380783 -0.315013  0.330155 -0.509374 -0.086197 -0.627978   \n",
       " 165061 -0.400975 -0.626943  1.555339 -2.017772 -0.107769  0.168310  0.017959   \n",
       " 238186  0.072509  0.820566 -0.561351 -0.709897  1.080399 -0.359429  0.787858   \n",
       " 150562 -0.535045  1.014587  1.750679  2.769390  0.500089  1.002270  0.847902   \n",
       " 138452 -4.026938  1.897371 -0.429786 -0.029571 -0.855751 -0.480406 -0.435632   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 119879  1.173488  0.100792  0.490512  0.461596 -0.296377 -0.213165 -0.165254   \n",
       " 259178 -0.775981  0.144023 -1.142399 -1.241113  1.940358  3.912076 -0.466107   \n",
       " 131932 -0.146609  0.992946  1.524591  0.485774  0.349308 -0.815198  1.076640   \n",
       " 146867 -2.948638  2.354849 -2.521201 -3.798905  1.866302  2.727695 -0.471769   \n",
       " 121958  1.233174 -0.784851  0.386784 -0.698559 -1.034018 -0.637028 -0.502369   \n",
       " \n",
       "               V8        V9       V10  ...       V20       V21       V22  \\\n",
       " 223361  0.035994  1.054560 -0.030441  ... -0.125390  0.238197  0.968305   \n",
       " 165061 -0.401619  0.040378  0.611115  ... -0.470372 -0.153485  0.421703   \n",
       " 238186  0.117276 -0.131275 -0.638222  ...  0.012227 -0.314638 -0.872959   \n",
       " 150562 -0.081323  0.371579  0.560595  ... -0.253757  0.063525  0.443431   \n",
       " 138452  1.313760  0.536044  1.221746  ... -0.012320 -0.480691 -0.230369   \n",
       " ...          ...       ...       ...  ...       ...       ...       ...   \n",
       " 119879  0.119221 -0.114199  0.079128  ... -0.157534 -0.186027 -0.574283   \n",
       " 259178  1.360620  0.400697 -0.654029  ... -0.295730  0.037078 -0.019575   \n",
       " 131932 -0.395316 -0.491303 -0.212753  ...  0.007155  0.052649  0.354089   \n",
       " 146867  2.217537  0.580199 -0.027572  ...  0.417396 -0.332759 -1.047514   \n",
       " 121958 -0.188057 -0.749637  0.543016  ...  0.337732  0.027634 -0.234522   \n",
       " \n",
       "              V23       V24       V25       V26       V27       V28  Class  \n",
       " 223361  0.053208 -0.278602 -0.044999 -0.216780  0.045168 -0.047145      0  \n",
       " 165061  0.113442 -1.004095 -1.176695  0.361924 -0.370469 -0.144792      0  \n",
       " 238186  0.083391  0.148178 -0.431459  0.119690  0.206395  0.070288      0  \n",
       " 150562 -0.072754  0.448192 -0.655203 -0.181038 -0.093013 -0.064931      0  \n",
       " 138452  0.250717  0.066399  0.470787  0.245335  0.286904 -0.322672      0  \n",
       " ...          ...       ...       ...       ...       ...       ...    ...  \n",
       " 119879  0.161405 -0.006140  0.091444  0.109235 -0.020922  0.003967      0  \n",
       " 259178  0.241830  0.682820 -1.635109 -0.770941  0.066006  0.137056      0  \n",
       " 131932 -0.291198  0.402849  0.237383 -0.398467 -0.121139 -0.196195      0  \n",
       " 146867  0.143326  0.678869  0.319710  0.426309  0.496912  0.335822      0  \n",
       " 121958 -0.059544 -0.109073  0.290326 -0.393074  0.001217  0.038588      0  \n",
       " \n",
       " [227845 rows x 29 columns],\n",
       "                V1        V2         V3        V4         V5        V6  \\\n",
       " 43428  -16.526507  8.584972 -18.649853  9.505594 -13.793819 -2.832404   \n",
       " 49906    0.339812 -2.743745  -0.134070 -1.385729  -1.451413  1.015887   \n",
       " 29474    1.399590 -0.590701   0.168619 -1.029950  -0.539806  0.040444   \n",
       " 276481  -0.432071  1.647895  -1.669361 -0.349504   0.785785 -0.630647   \n",
       " 278846   2.014160 -0.137394  -1.015839  0.327269  -0.182179 -0.956571   \n",
       " ...           ...       ...        ...       ...        ...       ...   \n",
       " 75723   -1.994348  1.503076  -0.365560  0.780223  -0.957956  0.038648   \n",
       " 252263  -0.234567  0.733694   0.486250 -0.718186   0.782227 -0.788837   \n",
       " 221246   0.040441 -0.109737  -1.266430  1.004783   2.223390 -0.670372   \n",
       " 81910   -0.495048  0.991481   1.671584 -0.342474   0.470012 -0.348503   \n",
       " 59490   -1.590486  0.992415  -0.512841  1.120752  -1.916756  3.142176   \n",
       " \n",
       "                V7        V8        V9        V10  ...       V20       V21  \\\n",
       " 43428  -16.701694  7.517344 -8.507059 -14.110184  ... -1.514923  1.190739   \n",
       " 49906   -0.524379  0.224060  0.899746  -0.565012  ...  0.506044 -0.213436   \n",
       " 29474   -0.712567  0.002299 -0.971747   0.756801  ...  0.212877  0.102398   \n",
       " 276481   0.276990  0.586025 -0.484715  -1.376648  ... -0.244633  0.358932   \n",
       " 278846   0.043241 -0.160746  0.363241   0.259452  ... -0.255293 -0.238644   \n",
       " ...           ...       ...       ...        ...  ...       ...       ...   \n",
       " 75723   -0.453702  1.553565 -0.561964  -0.100318  ... -0.316016  0.224820   \n",
       " 252263   1.056307 -0.175016 -0.244864  -0.708527  ... -0.127503 -0.202040   \n",
       " 221246   0.490662 -0.033739 -0.307052   0.402303  ... -0.008625  0.341151   \n",
       " 81910    0.996077 -0.351891 -0.219231   0.579396  ...  0.424562 -0.324995   \n",
       " 59490    2.120463 -3.819649  0.209349  -0.028753  ... -0.587066 -1.822474   \n",
       " \n",
       "              V22       V23       V24       V25       V26       V27       V28  \\\n",
       " 43428  -1.127670 -2.358579  0.673461 -1.413700 -0.462762 -2.018575 -1.042804   \n",
       " 49906  -0.942525 -0.526819 -1.156992  0.311211 -0.746647  0.040996  0.102038   \n",
       " 29474   0.168269 -0.166639 -0.810250  0.505083 -0.232340  0.011409  0.004634   \n",
       " 276481  0.873663 -0.178642 -0.017171 -0.207392 -0.157756 -0.237386  0.001934   \n",
       " 278846 -0.616400  0.347045  0.061561 -0.360196  0.174730 -0.078043 -0.070571   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 75723   0.319275 -0.081356 -0.366704 -0.269380 -0.278170  0.082042 -0.015071   \n",
       " 252263 -0.574857 -0.024845 -0.428558 -0.563551  0.159926  0.094924  0.163736   \n",
       " 221246  0.930041  0.162391 -1.180279 -1.484172 -0.619133  0.357845  0.354379   \n",
       " 81910  -0.474178 -0.145562 -0.011279 -0.162997  0.020511  0.040529 -0.269775   \n",
       " 59490   0.108047 -3.362671 -1.076905 -0.869555 -0.307649  0.125750 -0.607226   \n",
       " \n",
       "         Class  \n",
       " 43428       1  \n",
       " 49906       0  \n",
       " 29474       0  \n",
       " 276481      0  \n",
       " 278846      0  \n",
       " ...       ...  \n",
       " 75723       0  \n",
       " 252263      0  \n",
       " 221246      0  \n",
       " 81910       0  \n",
       " 59490       0  \n",
       " \n",
       " [56962 rows x 29 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, train_size=0.8, random_state=42 ,shuffle=True, stratify=None)\n",
    "print(\"Size(rows) of training data is\",len(X_train))\n",
    "print(\"Size(rows) of testing data is\",len(X_test))\n",
    "print(\"Data types of training data(X) are \",X_train.dtypes)\n",
    "print(\"Data types of training data(X) are \",X_train.describe)\n",
    "print(\"                            \")\n",
    "print(\"Data types of testing data(X) are \",X_test.dtypes)\n",
    "print(\"Data types of testing  data(X) are \",X_train.describe)\n",
    "print(\"                            \")\n",
    "X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  MLP Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is = 0.9998771110564938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Actual Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted Class  Actual Class\n",
       "43428                 1             1\n",
       "49906                 0             0\n",
       "29474                 0             0\n",
       "276481                0             0\n",
       "278846                0             0\n",
       "...                 ...           ...\n",
       "75723                 0             0\n",
       "252263                0             0\n",
       "221246                0             0\n",
       "81910                 0             0\n",
       "59490                 0             0\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=42, max_iter=10,hidden_layer_sizes=(10,2), solver='adam', shuffle=True).fit(X_train, Y_train)\n",
    "#clf.predict_proba(X_test)\n",
    "a=clf.predict(X_test)\n",
    "r=pd.DataFrame({'Predicted Class': a,'Actual Class': Y_test })\n",
    "print(\"Accuracy is =\", clf.score(X_test, Y_test))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is = 0.9999648888732839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Actual Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted Class  Actual Class\n",
       "43428                 1             1\n",
       "49906                 0             0\n",
       "29474                 0             0\n",
       "276481                0             0\n",
       "278846                0             0\n",
       "...                 ...           ...\n",
       "75723                 0             0\n",
       "252263                0             0\n",
       "221246                0             0\n",
       "81910                 0             0\n",
       "59490                 0             0\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, train_size=0.8, random_state=42 ,shuffle=True, stratify=None)\n",
    "clf = MLPClassifier(random_state=42, max_iter=20,hidden_layer_sizes=(28,2), solver='adam', alpha=0.0001,).fit(X_train, Y_train)\n",
    "#clf.predict_proba(X_test)\n",
    "a=clf.predict(X_test)\n",
    "r=pd.DataFrame({'Predicted Class': a,'Actual Class': Y_test })\n",
    "print(\"Accuracy is =\", clf.score(X_test, Y_test))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is = 0.999982444436642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Actual Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted Class  Actual Class\n",
       "43428                 1             1\n",
       "49906                 0             0\n",
       "29474                 0             0\n",
       "276481                0             0\n",
       "278846                0             0\n",
       "...                 ...           ...\n",
       "75723                 0             0\n",
       "252263                0             0\n",
       "221246                0             0\n",
       "81910                 0             0\n",
       "59490                 0             0\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, train_size=0.8, random_state=42 ,shuffle=True, stratify=None)\n",
    "clf = MLPClassifier(random_state=42, max_iter=50,hidden_layer_sizes=(28,5,2), solver='adam', alpha=0.0001,).fit(X_train, Y_train)\n",
    "#clf.predict_proba(X_test)\n",
    "a=clf.predict(X_test)\n",
    "r=pd.DataFrame({'Predicted Class': a,'Actual Class': Y_test })\n",
    "print(\"Accuracy is =\", clf.score(X_test, Y_test))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is = 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Actual Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted Class  Actual Class\n",
       "43428                 1             1\n",
       "49906                 0             0\n",
       "29474                 0             0\n",
       "276481                0             0\n",
       "278846                0             0\n",
       "...                 ...           ...\n",
       "75723                 0             0\n",
       "252263                0             0\n",
       "221246                0             0\n",
       "81910                 0             0\n",
       "59490                 0             0\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, train_size=0.8, random_state=42 ,shuffle=True, stratify=None)\n",
    "clf = MLPClassifier(random_state=42, max_iter=100,hidden_layer_sizes=(50,5), solver='adam', alpha=0.0001,).fit(X_train, Y_train)\n",
    "#clf.predict_proba(X_test)\n",
    "a=clf.predict(X_test)\n",
    "r=pd.DataFrame({'Predicted Class': a,'Actual Class': Y_test })\n",
    "print(\"Accuracy is =\", clf.score(X_test, Y_test))\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as we are incresing the size of hidden layer we are getting more accurate values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of testing  model =  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Class</th>\n",
       "      <th>Predicted Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original Class  Predicted Class\n",
       "43428                1                1\n",
       "49906                0                0\n",
       "29474                0                0\n",
       "276481               0                0\n",
       "278846               0                0\n",
       "...                ...              ...\n",
       "75723                0                0\n",
       "252263               0                0\n",
       "221246               0                0\n",
       "81910                0                0\n",
       "59490                0                0\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=50,solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "b=model.predict(X_test)\n",
    "d=pd.DataFrame({'Original Class': Y_test, 'Predicted Class': b})\n",
    "c=accuracy_score(b,Y_test)\n",
    "print(\"Accuracy score of testing  model = \",c)  # Accuracy is 99.8%  \n",
    "X_test,Y_test\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of testing  model =  1.0\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=40,solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "b=model.predict(X_test)\n",
    "pd.DataFrame({'Original Class': Y_test, 'Predicted Class': b})\n",
    "c=accuracy_score(b,Y_test)\n",
    "print(\"Accuracy score of testing  model = \",c)  # Accuracy is 99.8%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of testing  model =  1.0\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=20,solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "b=model.predict(X_test)\n",
    "pd.DataFrame({'Original Class': Y_test, 'Predicted Class': b})\n",
    "c=accuracy_score(b,Y_test)\n",
    "print(\"Accuracy score of testing  model = \",c)  # Accuracy is 99.8%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of testing  model =  1.0\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=100,solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "b=model.predict(X_test)\n",
    "pd.DataFrame({'Original Class': Y_test, 'Predicted Class': b})\n",
    "c=accuracy_score(b,Y_test)\n",
    "print(\"Accuracy score of testing  model = \",c)  # Accuracy is 99.8%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is  [[56864     0]\n",
      " [    0    98]]\n",
      "The precision on training data is : 1.0\n",
      "The recall on training data is : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_matrix_test = confusion_matrix(Y_test,b)\n",
    "print(\"Confusion Matrix is \", cm_matrix_test)\n",
    "cm_display = ConfusionMatrixDisplay(cm_matrix_test).plot()\n",
    "precision = precision_score(Y_test,b)\n",
    "print(f\"The precision on training data is : {round(precision, 3)}\")\n",
    "recall = recall_score(Y_test, b)\n",
    "print(f\"The recall on training data is : {round(recall, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
